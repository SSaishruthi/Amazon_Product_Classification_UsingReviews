{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ss/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import gzip\n",
    "from sklearn.utils import shuffle\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df1 = getDF('Automotive.json.gz')\n",
    "df2 = getDF('Cloth_shoes.json.gz')\n",
    "df3 = getDF('Digi_Mus.json.gz')\n",
    "df4 = getDF('Electronics.json.gz')\n",
    "df5 = getDF('garden.json.gz')\n",
    "df6 = getDF('health.json.gz')\n",
    "df7 = getDF('home_kitchen.json.gz')\n",
    "df8 = getDF('kindle.json.gz')\n",
    "df9 = getDF('office_prod.json.gz')\n",
    "df10 = getDF('pet_supply.json.gz')\n",
    "df11 = getDF('tools.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels1 = ['Automotive', 'Cloth_shoes', 'Digi_Mus', 'Electronics', 'garden', 'health', 'home_kitchen', 'kindle', 'office_prod', 'pet_supply', 'tools']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['Class'] = 'Automotive'\n",
    "df2['Class'] = 'Cloth_shoes'\n",
    "df3['Class'] = 'Digi_Mus'\n",
    "df4['Class'] = 'Electronics'\n",
    "df5['Class'] = 'garden'\n",
    "df6['Class'] = 'health'\n",
    "df7['Class'] = 'home_kitchen'\n",
    "df8['Class'] = 'kindle'\n",
    "df9['Class'] = 'office_prod'\n",
    "df10['Class'] = 'pet_supply'\n",
    "df11['Class'] = 'tools'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1_split = df1[0:10000]\n",
    "df2_split = df2[0:10000]\n",
    "df3_split = df3[0:10000]\n",
    "df4_split = df4[0:10000]\n",
    "df5_split = df5[0:10000]\n",
    "df6_split = df6[0:10000]\n",
    "df7_split = df7[0:10000]\n",
    "df8_split = df8[0:10000]\n",
    "df9_split = df9[0:10000]\n",
    "df10_split = df10[0:10000]\n",
    "df11_split = df11[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [df1_split, df2_split, df3_split, df4_split, df5_split, df6_split, df7_split, df8_split, df9_split, df10_split, df11_split]\n",
    "df = pd.concat(frames)\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_x, ts_x, tr_y, ts_y = train_test_split(df['reviewText'], df['Class'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ts_x = pd.DataFrame(ts_x)\n",
    "df_ts_y = pd.DataFrame(ts_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni_vectorizer = CountVectorizer(min_df=1, stop_words='english')\n",
    "bi_vectorizer = CountVectorizer(ngram_range=(1, 2), min_df=1, stop_words='english')\n",
    "tri_vectorizer = CountVectorizer(ngram_range=(1, 3), min_df=1, stop_words='english')\n",
    "four_vectorizer = CountVectorizer(ngram_range=(1, 4), min_df=1, stop_words='english')\n",
    "\n",
    "\n",
    "\n",
    "cls = BernoulliNB()\n",
    "\n",
    "unigram_pred = Pipeline([\n",
    "    ('vect', uni_vectorizer),\n",
    "    ('classifier', cls)\n",
    "])\n",
    "\n",
    "bigram_pred = Pipeline([\n",
    "    ('vect', bi_vectorizer),\n",
    "    ('classifier', cls)\n",
    "])\n",
    "\n",
    "trigram_pred = Pipeline([\n",
    "    ('vect', tri_vectorizer),\n",
    "    ('classifier', cls)\n",
    "])\n",
    "\n",
    "fourgram_pred = Pipeline([\n",
    "    ('vect', four_vectorizer),\n",
    "    ('classifier', cls)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNIGRAM NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cross_validation scores', array([ 0.78352273,  0.78386364,  0.78276515,  0.77829545,  0.78193182]))\n",
      "['Automotive', 'Cloth_shoes', 'Digi_Mus', 'Electronics', 'garden', 'health', 'home_kitchen', 'kindle', 'office_prod', 'pet_supply', 'tools']\n",
      "[[1687  144    0   19   45   27   24    0    5   22   50]\n",
      " [   4 1893    0   20   14   10    3    1    5    1    6]\n",
      " [   7  178 1719   61    0   10    4   19    0    9    3]\n",
      " [ 183  343    3 1301    1   60    3    0   72   16   29]\n",
      " [ 171  148    0    1 1313   68   91    0    7  173   60]\n",
      " [  83  244    1   29   49 1433   54    0   12   50   17]\n",
      " [  29  156    0    2   40   49 1651    2    9   28   25]\n",
      " [  10  186    6   13    0    8    4 1754    8    4    1]\n",
      " [  42  266    2   43   17   52   12    1 1506   11   38]\n",
      " [  44  100    0    1   91   46    5    0    2 1757    5]\n",
      " [ 244  211    0   17   30   58   26    1   16   24 1342]]\n",
      "('Accuracy score is', 0.78890909090909089)\n"
     ]
    }
   ],
   "source": [
    "#CROSS VALIDATION\n",
    "cv1 = ShuffleSplit(n_splits=5, test_size = 0.3, random_state=0)\n",
    "scores = cross_val_score(unigram_pred, tr_x, tr_y, cv=cv1)\n",
    "print ('cross_validation scores', scores)\n",
    "#\n",
    "unigram_pred.fit(tr_x, tr_y)\n",
    "unigram_result = unigram_pred.predict(ts_x)\n",
    "print(labels1)\n",
    "confusion_matrix = metrics.confusion_matrix(ts_y, unigram_result, labels=labels1)\n",
    "print (confusion_matrix)\n",
    "score = metrics.accuracy_score(ts_y, unigram_result)\n",
    "print('Accuracy score is', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIGRAM NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cross_validation scores', array([ 0.70170455,  0.67204545,  0.63253788,  0.63575758,  0.62409091]))\n",
      "['Automotive', 'Cloth_shoes', 'Digi_Mus', 'Electronics', 'garden', 'health', 'home_kitchen', 'kindle', 'office_prod', 'pet_supply', 'tools']\n",
      "('confusion matrix is', array([[1468,  441,    0,    6,   10,   41,   12,    0,    5,   15,   25],\n",
      "       [   0, 1939,    0,    7,    3,    2,    2,    0,    0,    0,    4],\n",
      "       [   1,  489, 1480,   17,    0,   11,    1,   10,    1,    0,    0],\n",
      "       [ 129,  780,    2,  975,    0,   68,    1,    0,   36,    4,   16],\n",
      "       [ 157,  451,    0,    1,  911,  126,  126,    0,    4,  188,   68],\n",
      "       [  41,  505,    0,    7,   13, 1342,   27,    0,    1,   22,   14],\n",
      "       [  14,  410,    0,    0,    9,   51, 1480,    1,    3,    9,   14],\n",
      "       [   3,  495,    0,    5,    0,    3,    4, 1481,    2,    1,    0],\n",
      "       [  25,  609,    1,   24,    3,   45,   15,    1, 1244,    3,   20],\n",
      "       [  20,  331,    0,    1,   16,   45,    6,    0,    0, 1625,    7],\n",
      "       [ 158,  597,    0,    5,    5,   60,   22,    1,    9,   10, 1102]]))\n",
      "('Accuracy score is', 0.68395454545454548)\n"
     ]
    }
   ],
   "source": [
    "#CROSS VALIDATION\n",
    "cv1 = ShuffleSplit(n_splits=5, test_size = 0.3, random_state=0)\n",
    "scores = cross_val_score(bigram_pred, tr_x, tr_y, cv=cv1)\n",
    "print ('cross_validation scores', scores)\n",
    "#\n",
    "bigram_pred.fit(tr_x, tr_y)\n",
    "bigram_result = bigram_pred.predict(ts_x)\n",
    "print(labels1)\n",
    "confusion_matrix = metrics.confusion_matrix(ts_y, bigram_result, labels=labels1)\n",
    "print ('confusion matrix is', confusion_matrix)\n",
    "score = metrics.accuracy_score(ts_y, bigram_result)\n",
    "print('Accuracy score is', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRIGRAM NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('cross_validation scores', array([ 0.4994697 ,  0.43265152,  0.50109848,  0.55121212,  0.55549242]))\n",
      "['Automotive', 'Cloth_shoes', 'Digi_Mus', 'Electronics', 'garden', 'health', 'home_kitchen', 'kindle', 'office_prod', 'pet_supply', 'tools']\n",
      "('confusion matrix is', array([[1177,  761,    0,    5,    2,    9,    2,    0,    0,   39,   17],\n",
      "       [   0, 1954,    0,    2,    0,    0,    0,    0,    2,    0,    1],\n",
      "       [   1,  846, 1130,    8,    0,    1,    0,   39,    0,    0,    0],\n",
      "       [  86, 1136,    0,  716,    0,   25,    1,    0,   11,   32,   16],\n",
      "       [ 148,  671,    0,    0,  566,   27,   88,    0,    0,  471,   59],\n",
      "       [  29,  966,    0,    5,    6,  877,   14,    0,    0,  106,    6],\n",
      "       [  14,  792,    0,    0,    2,   17, 1121,    0,    2,   48,   12],\n",
      "       [   3,  774,    0,    6,    0,    2,    1, 1175,    0,    1,    0],\n",
      "       [  24, 1113,    1,   31,    1,   16,   12,    1,  803,   37,   20],\n",
      "       [   2,  385,    0,    0,    4,   10,    0,    0,    1, 1546,    0],\n",
      "       [ 108,  943,    0,    1,    2,   15,    3,    1,    1,   35,  856]]))\n",
      "('Accuracy score is', 0.54186363636363633)\n"
     ]
    }
   ],
   "source": [
    "#CROSS VALIDATION\n",
    "cv1 = ShuffleSplit(n_splits=5, test_size = 0.3, random_state=0)\n",
    "scores = cross_val_score(trigram_pred, tr_x, tr_y, cv=cv1)\n",
    "print ('cross_validation scores', scores)\n",
    "#\n",
    "trigram_pred.fit(tr_x, tr_y)\n",
    "trigram_result = trigram_pred.predict(ts_x)\n",
    "print(labels1)\n",
    "confusion_matrix = metrics.confusion_matrix(ts_y, trigram_result, labels=labels1)\n",
    "print ('confusion matrix is', confusion_matrix)\n",
    "score = metrics.accuracy_score(ts_y, trigram_result)\n",
    "print('Accuracy score is', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
